{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "bg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    # initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff,threshold,255,\n",
    "                                cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    #edged = cv2.Canny(gray, 30, 150)\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    (cnts, _) = cv2.findContours(thresholded.copy(),\n",
    "                                 cv2.RETR_EXTERNAL,\n",
    "                                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # initialize weight for running average\n",
    "    aWeight = 0.5\n",
    "\n",
    "    # get the reference to the webcam\n",
    "    # camera = cv2.VideoCapture(0)\n",
    "\n",
    "    # region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "\n",
    "    # initialize num of frames\n",
    "    num_frames = 0\n",
    "    image_num = 0\n",
    "\n",
    "    start_recording = False\n",
    "\n",
    "    # keep looping, until interrupted\n",
    "    while(True):\n",
    "        # get the current frame\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if (grabbed == True):\n",
    "\n",
    "            # resize the frame\n",
    "            frame = imutils.resize(frame, width=700)\n",
    "\n",
    "            # flip the frame so that it is not the mirror view\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # clone the frame\n",
    "            clone = frame.copy()\n",
    "\n",
    "            # get the height and width of the frame\n",
    "            (height, width) = frame.shape[:2]\n",
    "\n",
    "            # get the ROI\n",
    "            roi = frame[top:bottom, right:left]\n",
    "\n",
    "            # convert the roi to grayscale and blur it\n",
    "            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "            # to get the background, keep looking till a threshold is reached\n",
    "            # so that our running average model gets calibrated\n",
    "            if num_frames < 30:\n",
    "                run_avg(gray, aWeight)\n",
    "                print(num_frames)\n",
    "            else:\n",
    "                # segment the hand region\n",
    "                hand = segment(gray)\n",
    "\n",
    "                # check whether hand region is segmented\n",
    "                if hand is not None:\n",
    "                    # if yes, unpack the thresholded image and\n",
    "                    # segmented region\n",
    "                    (thresholded, segmented) = hand\n",
    "\n",
    "                    # draw the segmented region and display the frame\n",
    "                    cv2.drawContours(\n",
    "                        clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "                    if start_recording:\n",
    "\n",
    "                        # Mention the directory in which you wanna store the images followed by the image name\n",
    "                        cv2.imwrite(r\"C:\\Users\\spider\\Documents\\Springboard\\GitHub\\Hand-Guesture-Recognition\\Dataset\\help\\h_\" +\n",
    "                                    str(image_num) + '.png', thresholded)\n",
    "                        image_num += 1\n",
    "                    #winname = \"Thesholded\"\n",
    "                    #cv2.namedWindow(winname)       \n",
    "                    #cv2.moveWindow(winname, 50,60)  \n",
    "                    #cv2.imshow(winname, thresholded)\n",
    "                    cv2.imshow(\"Thesholded\", thresholded)\n",
    "\n",
    "            # draw the segmented hand\n",
    "            cv2.rectangle(clone, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # increment the number of frames\n",
    "            num_frames += 1\n",
    "\n",
    "            # display the frame with segmented hand\n",
    "            #winname = \"Video Feed\"\n",
    "            #cv2.namedWindow(winname)       \n",
    "            #cv2.moveWindow(winname, 50,60)\n",
    "            cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "            # observe the keypress by the user\n",
    "            keypress = cv2.waitKey(10) & 0xFF\n",
    "\n",
    "            # if the user pressed \"q\", then stop looping\n",
    "            if keypress == ord(\"q\") or image_num > 1000:\n",
    "                break\n",
    "\n",
    "            if keypress == ord(\"s\"):\n",
    "                start_recording = True\n",
    "\n",
    "        else:\n",
    "            print(\"[Warning!] Error input, Please check your(camra Or video)\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "\n",
    "# free up memory\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
